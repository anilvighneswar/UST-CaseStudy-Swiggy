{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebd418cf-5d2b-43df-88bf-1ed2dcbb4086",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Dependencies for File access"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-storage-file-datalake in /databricks/python3/lib/python3.11/site-packages (12.14.0)\nRequirement already satisfied: azure-core<2.0.0,>=1.28.0 in /databricks/python3/lib/python3.11/site-packages (from azure-storage-file-datalake) (1.30.2)\nRequirement already satisfied: azure-storage-blob<13.0.0,>=12.19.0 in /databricks/python3/lib/python3.11/site-packages (from azure-storage-file-datalake) (12.19.1)\nRequirement already satisfied: typing-extensions>=4.3.0 in /databricks/python3/lib/python3.11/site-packages (from azure-storage-file-datalake) (4.10.0)\nRequirement already satisfied: isodate>=0.6.1 in /databricks/python3/lib/python3.11/site-packages (from azure-storage-file-datalake) (0.6.1)\nRequirement already satisfied: requests>=2.21.0 in /databricks/python3/lib/python3.11/site-packages (from azure-core<2.0.0,>=1.28.0->azure-storage-file-datalake) (2.31.0)\nRequirement already satisfied: six>=1.11.0 in /usr/lib/python3/dist-packages (from azure-core<2.0.0,>=1.28.0->azure-storage-file-datalake) (1.16.0)\nRequirement already satisfied: cryptography>=2.1.4 in /databricks/python3/lib/python3.11/site-packages (from azure-storage-blob<13.0.0,>=12.19.0->azure-storage-file-datalake) (41.0.3)\nRequirement already satisfied: cffi>=1.12 in /databricks/python3/lib/python3.11/site-packages (from cryptography>=2.1.4->azure-storage-blob<13.0.0,>=12.19.0->azure-storage-file-datalake) (1.15.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.11/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-storage-file-datalake) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.11/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-storage-file-datalake) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.11/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-storage-file-datalake) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.11/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.28.0->azure-storage-file-datalake) (2023.7.22)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob<13.0.0,>=12.19.0->azure-storage-file-datalake) (2.21)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: pycryptodome in /local_disk0/.ephemeral_nfs/envs/pythonEnv-58c1d8e0-bbcd-42d4-81f1-d0a898bd5965/lib/python3.11/site-packages (3.21.0)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install azure-storage-file-datalake\n",
    "!pip install pycryptodome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0c436a1-9eda-427b-a4b7-2833995ef8ec",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Imports"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from functools import reduce\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import *\n",
    "import json\n",
    "import chardet\n",
    "from azure.storage.filedatalake import DataLakeServiceClient, FileSystemClient, DataLakeFileClient\n",
    "from Crypto.Cipher import AES\n",
    "import base64\n",
    "import os\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f7e6410-bbc5-4522-8c2e-a61d1e78a502",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "getting credentials from secrets"
    }
   },
   "outputs": [],
   "source": [
    "CONNECTION_STRING = dbutils.secrets.get(scope = 'az_cs_scope', key= 'conn-str')\n",
    "ACCOUNT_KEY = dbutils.secrets.get(scope = 'az_cs_scope', key= 'acc-key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "afc96613-6834-438f-82c2-ebd79e99800f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Fetching file"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ascii\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOStream.flush timed out\n"
     ]
    }
   ],
   "source": [
    "ACCOUNT_NAME = \"cs0st0rage\"\n",
    " \n",
    "# Initialize DataLakeServiceClient for Azure Data Lake Storage Gen2\n",
    "data_lake_service_client = DataLakeServiceClient.from_connection_string(CONNECTION_STRING)\n",
    " \n",
    "# Name of the filesystem (similar to container) where files are stored\n",
    "file_system_name = \"rawdata\"\n",
    " \n",
    " \n",
    "def download_and_parse_json(file_system_name, file_path):\n",
    "    file_client = data_lake_service_client.get_file_system_client(file_system_name).get_file_client(file_path)\n",
    "    try:\n",
    "        # Download the JSON data as bytes\n",
    "        file_data = file_client.download_file().readall()\n",
    "        # Decode the bytes to a string and load it as JSON\n",
    "        enc = chardet.detect(file_data)\n",
    "        enc_format = enc.get(\"encoding\", \"utf-8\") \n",
    "        print(enc_format)\n",
    "        json_data = json.loads(file_data.decode(enc_format))\n",
    "        return json_data\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download and parse JSON: {e}\")\n",
    "        return None\n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    data = download_and_parse_json(file_system_name, \"jsondata/data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cce3dd2-e407-4433-b629-3e548a700f7d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "JSON flattening"
    }
   },
   "outputs": [],
   "source": [
    "records_restaurant = []\n",
    "records_menu = []\n",
    "\n",
    "for city_name, city_data in data.items():\n",
    "    if isinstance(city_data, dict) and \"restaurants\" in city_data:\n",
    "        full_city_name = city_name\n",
    "\n",
    "        for restaurant_id, restaurant_data in city_data.get(\"restaurants\", {}).items():\n",
    "            records_restaurant.append(\n",
    "                {\n",
    "                    \"Restaurant_ID\": restaurant_id,\n",
    "                    \"Restaurant_Name\": restaurant_data.get(\"name\"),\n",
    "                    \"City\": full_city_name,\n",
    "                    \"Rating\": restaurant_data.get(\"rating\"),\n",
    "                    \"Rating_Count\": restaurant_data.get(\"rating_count\"),\n",
    "                    \"Cost\": restaurant_data.get(\"cost\"),\n",
    "                    \"Cuisine\": restaurant_data.get(\"cuisine\"),\n",
    "                    \"Lic_No\": restaurant_data.get(\"lic_no\"),\n",
    "                    \"Link\": restaurant_data.get(\"link\"),\n",
    "                    \"Address\": restaurant_data.get(\"address\"),\n",
    "                }\n",
    "            )\n",
    "\n",
    "            for category, items in restaurant_data.get(\"menu\", {}).items():\n",
    "                for item_name, item_data in items.items():\n",
    "                    records_menu.append(\n",
    "                        {\n",
    "                            \"Restaurant_ID\": restaurant_id,\n",
    "                            \"Category\": category,\n",
    "                            \"Item_Name\": item_name,\n",
    "                            \"Price\": item_data.get(\"price\"),\n",
    "                            \"Veg_or_Non_Veg\": item_data.get(\"veg_or_non_veg\")\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "    elif isinstance(city_data, dict):\n",
    "        for sub_area_name, sub_area_data in city_data.items():\n",
    "            full_city_name = f\"{sub_area_name},{city_name}\"\n",
    "\n",
    "            for restaurant_id, restaurant_data in sub_area_data.get(\n",
    "                \"restaurants\", {}\n",
    "            ).items():\n",
    "                records_restaurant.append(\n",
    "                    {\n",
    "                        \"Restaurant_ID\": restaurant_id,\n",
    "                        \"Restaurant_Name\": restaurant_data.get(\"name\"),\n",
    "                        \"City\": full_city_name,\n",
    "                        \"Rating\": restaurant_data.get(\"rating\"),\n",
    "                        \"Rating_Count\": restaurant_data.get(\"rating_count\"),\n",
    "                        \"Cost\": restaurant_data.get(\"cost\"),\n",
    "                        \"Cuisine\": restaurant_data.get(\"cuisine\"),\n",
    "                        \"Lic_No\": restaurant_data.get(\"lic_no\"),\n",
    "                        \"Link\": restaurant_data.get(\"link\"),\n",
    "                        \"Address\": restaurant_data.get(\"address\"),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                for category, items in restaurant_data.get(\"menu\", {}).items():\n",
    "                    for item_name, item_data in items.items():\n",
    "                        records_menu.append(\n",
    "                            {\n",
    "                                \"Restaurant_ID\": restaurant_id,\n",
    "                                \"Category\": category,\n",
    "                                \"Item_Name\": item_name,\n",
    "                                \"Price\": item_data.get(\"price\"),\n",
    "                                \"Veg_or_Non_Veg\": item_data.get(\"veg_or_non_veg\")\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "df_restaurant = spark.createDataFrame(records_restaurant)\n",
    "df_menu = spark.createDataFrame(records_menu)\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd5de084-6202-4cf3-ba25-408497130f1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_restaurant.display()\n",
    "# df_menu.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "batchId": -4318137229471456,
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b77be4f3-f430-4fe2-b291-dbba113e1274",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Shape of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc6be943-f6fa-4449-a855-69968abb5c1b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Restaurant DataFrame"
    }
   },
   "outputs": [],
   "source": [
    "# print(df_restaurant.count())\n",
    "# print(len(df_restaurant.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcde2c36-00ff-4288-970b-34635be43e18",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Menu DataFrame"
    }
   },
   "outputs": [],
   "source": [
    "# print(df_menu.count())\n",
    "# print(len(df_menu.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "batchId": -4318137229471456,
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7184e36a-bcf2-431b-bdf7-a6fea049f92f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### NULL Handling\n",
    "  + Restaurant DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "290793f3-c447-4bc2-ab2a-96649c0bfb9c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Checking for NULLS"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+-------+------+----+------+------------+-------------+---------------+\n|Address|City| Cost|Cuisine|Lic_No|Link|Rating|Rating_Count|Restaurant_ID|Restaurant_Name|\n+-------+----+-----+-------+------+----+------+------------+-------------+---------------+\n|  25602|   0|25602|  25602| 25602|   0|     0|       25602|            0|              0|\n+-------+----+-----+-------+------+----+------+------------+-------------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "null_counts = df_restaurant.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in df_restaurant.columns])\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c90e6e65-219f-4211-98b2-a70289c8a7b1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "dropping nulls"
    }
   },
   "outputs": [],
   "source": [
    "df_restaurant = df_restaurant.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25a0ce18-684e-4254-8a37-96e737ac4d14",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "checking for placeholders"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----+-------+------+----+------+------------+-------------+---------------+\n|Address|City|Cost|Cuisine|Lic_No|Link|Rating|Rating_Count|Restaurant_ID|Restaurant_Name|\n+-------+----+----+-------+------+----+------+------------+-------------+---------------+\n|    106|   0| 151|    119|   253|   0|   106|         106|            0|            106|\n+-------+----+----+-------+------+----+------+------------+-------------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "rows_with_na = df_restaurant.select([sum(when(col(c)=='NA',1).otherwise(0)).alias(c) for c in df_restaurant.columns])\n",
    "rows_with_na.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83af7ecd-69fd-4748-8abc-e8c959378833",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_restaurant=df_restaurant.filter(col('Restaurant_name')!='NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb6ad917-cd89-4ba1-86f5-d4e49327e800",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "removing ₹ symbol"
    }
   },
   "outputs": [],
   "source": [
    "df_restaurant = df_restaurant.withColumn('Cost',regexp_replace('Cost','₹', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a610a613-49af-4339-9e21-41c28a5e057a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "city_medians = df_restaurant.filter(\n",
    "    (col(\"Cost\").isNotNull()) & ~(col(\"Cost\") == \"NA\")\n",
    ").groupBy(\"City\").agg(\n",
    "    expr('percentile_approx(Cost, 0.5)').alias('median_cost')\n",
    ")\n",
    "df_with_median = df_restaurant.join(\n",
    "    city_medians, on=\"City\", how=\"left\"\n",
    ")\n",
    "\n",
    "df_restaurant = df_with_median.withColumn(\n",
    "    \"Cost\",\n",
    "    coalesce(col(\"Cost\").cast(\"int\"), col(\"median_cost\"))\n",
    ").drop(\"median_cost\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c5ee207-1eda-41a1-add6-21fb651c7b42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_restaurant = df_restaurant.withColumn(\n",
    "    \"Lic_No\", \n",
    "    when((col(\"Lic_No\") == \"NA\") | (col(\"Lic_No\") == \"license\"), \"00000000000000\")\n",
    "    .otherwise(col(\"Lic_No\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1cadece-f7c3-41d1-bdac-85e18dda0079",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "checking for '--'"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+----+-------+------+----+------+------------+-------------+---------------+\n|City|Address|Cost|Cuisine|Lic_No|Link|Rating|Rating_Count|Restaurant_ID|Restaurant_Name|\n+----+-------+----+-------+------+----+------+------------+-------------+---------------+\n|   0|      0|   0|      0|     0|   0| 90784|           0|            0|              0|\n+----+-------+----+-------+------+----+------+------------+-------------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "df_restaurant.select([count(when(col(column) == '--', 1)).alias(column) for column in df_restaurant.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcb16a4d-f4f4-486c-9ad6-74aed3db5440",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "replacing '--' with 0"
    }
   },
   "outputs": [],
   "source": [
    "df_restaurant = df_restaurant.withColumn('Rating', when(col(\"Rating\") == '--', 0).otherwise(col(\"Rating\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd501e79-34e7-45b0-ad0b-7da56f6f25d2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "handling rating counts"
    }
   },
   "outputs": [],
   "source": [
    "df_restaurant = df_restaurant.withColumn(\n",
    "    'Rating_count',\n",
    "    when(\n",
    "        col('Rating_count').rlike('^\\\\d+\\\\+ ratings$'),\n",
    "        regexp_replace(col('Rating_count'), '\\\\+ ratings', '').cast('int')\n",
    "    )\n",
    "    .when(\n",
    "        col('Rating_count').rlike('^\\\\d+K\\\\+ ratings$'),\n",
    "        (regexp_replace(col('Rating_count'), 'K\\\\+ ratings', '') * 1000).cast('int')\n",
    "    )\n",
    "    .when(\n",
    "        col('Rating_count') == 'NA',\n",
    "        0\n",
    "    )\n",
    "    .when(\n",
    "        col('Rating_count') == 'Too Few Ratings',\n",
    "        0\n",
    "    )\n",
    "    .otherwise(None)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9ede00a-4a46-4274-8300-4adf65ccbcb9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "  + Menu DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "450e11fe-19cd-4d3a-9975-d00276bd7be0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "checking nulls in menu"
    }
   },
   "outputs": [],
   "source": [
    "# df_menu.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in df_menu.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1ad8351-79b5-46a2-a830-60a389d515db",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "checking na values in menu"
    }
   },
   "outputs": [],
   "source": [
    "# df_menu.select([sum(when(col(c)=='NA',1).otherwise(0)).alias(c) for c in df_menu.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ecf21095-a0e5-41e9-bc6e-fa4b75140764",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "checking -- in menu"
    }
   },
   "outputs": [],
   "source": [
    "# df_menu.select([count(when(col(c) == '--', 1)).alias(c) for c in df_menu.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9ae8104-1e24-4370-903c-c5ad0731c9a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Duplicate Data Handling\n",
    "  + Restaurant DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1439c49-3368-4caf-ba6f-89ca0aee6c8c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "checking for duplicates in rest"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5935"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_restaurant.groupBy('Restaurant_ID').count().filter(col(\"count\") > 1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "041e428e-3912-48a1-b378-a8b5434568f8",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "dropping duplicates in rest"
    }
   },
   "outputs": [],
   "source": [
    "df_restaurant = df_restaurant.dropDuplicates(['Restaurant_ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77143a8f-fdd6-42f4-81ae-e88941342442",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "  + menu_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46103b17-ba0f-4357-94ce-0b5d9fe6a228",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "checking for duplicates in menu"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "559515"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_menu.groupBy('Restaurant_ID','Category','Item_Name').count().filter(col(\"count\") > 1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94a55491-e164-4e3d-a3bb-98bb37b1148a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "dropping duplicates in menu"
    }
   },
   "outputs": [],
   "source": [
    "df_menu = df_menu.drop_duplicates(['Restaurant_ID','Category','Item_Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2129269-be42-4bdb-b22d-6847dd1f65e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Removing unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba3b5e36-916d-40e1-aca3-8dd218687fed",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "dropping city_link"
    }
   },
   "outputs": [],
   "source": [
    "df_restaurant = df_restaurant.drop('City_Link')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "724cc1b9-0219-409a-a456-8eaacd6ff035",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Defining Schema of DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89e8b784-f0aa-442e-aa21-ff126b6cf7df",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "old schema of rest"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- City: string (nullable = true)\n |-- Address: string (nullable = true)\n |-- Cost: double (nullable = true)\n |-- Cuisine: string (nullable = true)\n |-- Lic_No: string (nullable = true)\n |-- Link: string (nullable = true)\n |-- Rating: string (nullable = true)\n |-- Rating_count: integer (nullable = true)\n |-- Restaurant_ID: string (nullable = true)\n |-- Restaurant_Name: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df_restaurant.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f09782e8-e3b5-4c6c-a689-efadc0a076e8",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "corrected schema of rest"
    }
   },
   "outputs": [],
   "source": [
    "new_schema = StructType([\n",
    "    StructField(\"Address\", StringType(), True),\n",
    "    StructField(\"City\", StringType(), True),\n",
    "    StructField(\"Cost\", IntegerType(), True),              \n",
    "    StructField(\"Cuisine\", StringType(), True),\n",
    "    StructField(\"Lic_No\", StringType(), True),\n",
    "    StructField(\"Rating\", DoubleType(), True),            \n",
    "    StructField(\"Rating_count\", IntegerType(), True),    \n",
    "    StructField(\"Restaurant_ID\", IntegerType(), True),    \n",
    "    StructField(\"Restaurant_Name\", StringType(), True)\n",
    "])\n",
    " \n",
    "df_restaurant = df_restaurant.select(\n",
    "    [col(c.name).cast(c.dataType) for c in new_schema.fields]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0faea4d9-a09d-4326-9e61-a3fc17c8694c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "shape of new rest"
    }
   },
   "outputs": [],
   "source": [
    "# print(df_restaurant.count())\n",
    "# len(df_restaurant.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bdd2909-f849-4d53-8bd7-0679d5136c6a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "old schema of menu"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- Category: string (nullable = true)\n |-- Item_Name: string (nullable = true)\n |-- Price: string (nullable = true)\n |-- Restaurant_ID: string (nullable = true)\n |-- Veg_or_Non_Veg: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df_menu.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ac63c06-4802-4f63-8031-c04437cc50b3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "corrected schema of menu"
    }
   },
   "outputs": [],
   "source": [
    "new_schema = StructType([\n",
    "    StructField(\"Category\", StringType(), True),\n",
    "    StructField(\"Item_Name\", StringType(), True),\n",
    "    StructField(\"Price\", DoubleType(), True),              \n",
    "    StructField(\"Restaurant_ID\", IntegerType(), True),\n",
    "    StructField(\"Veg_or_Non_Veg\", StringType(), True)\n",
    "])\n",
    "\n",
    "df_menu = df_menu.select(\n",
    "    [col(field.name).cast(field.dataType).alias(field.name) for field in new_schema.fields]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac94e4ff-459e-416d-a9a3-73bee340185d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# print(df_menu.count())\n",
    "# len(df_menu.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "433a2e26-7e3a-49a6-b7cb-2b9004d96476",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Joining Rest and Menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "843cc4fb-5e6f-4005-825e-4597e4c75637",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "group menu items by rest id for joining"
    }
   },
   "outputs": [],
   "source": [
    "df_menu = df_menu.groupBy('Restaurant_ID').agg(\n",
    "    collect_list(\n",
    "        struct('Category', 'Item_Name', 'Price', 'Restaurant_ID', 'Veg_or_Non_Veg')\n",
    "    ).alias('Menu_Items'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37f393eb-461d-4039-8294-efc2aaebf1a1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "joining dataframes"
    }
   },
   "outputs": [],
   "source": [
    "df_final = df_restaurant.join(df_menu, on=\"Restaurant_ID\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "125c7a6c-89e1-4205-9c73-7a190d05ca26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# encryption of lic no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07eb587a-5358-4e56-b234-a94e55fb9329",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# AES encryption function\n",
    "def encrypt_lic_no(lic_no, key):\n",
    "    if lic_no is None:\n",
    "        return None\n",
    "    try:\n",
    "        # Ensure the key is exactly 16 bytes (128-bit key)\n",
    "        key = key.ljust(16)[:16].encode('utf-8')\n",
    "        cipher = AES.new(key, AES.MODE_ECB)  # AES encryption in ECB mode\n",
    "       \n",
    "        # Padding to make the input length a multiple of 16\n",
    "        padded_lic_no = lic_no.ljust(16 * ((len(lic_no) + 15) // 16))\n",
    "        encrypted_bytes = cipher.encrypt(padded_lic_no.encode('utf-8'))\n",
    "       \n",
    "        # Encode the encrypted bytes to Base64\n",
    "        encrypted_base64 = base64.b64encode(encrypted_bytes).decode('utf-8')\n",
    "        return encrypted_base64\n",
    "    except Exception as e:\n",
    "        return None\n",
    " \n",
    "# AES decryption function\n",
    "def decrypt_lic_no(encrypted_base64, key):\n",
    "    if encrypted_base64 is None:\n",
    "        return None\n",
    "    try:\n",
    "        # Ensure the key is exactly 16 bytes (128-bit key)\n",
    "        key = key.ljust(16)[:16].encode('utf-8')\n",
    "       \n",
    "        # Decode the Base64-encoded encrypted text\n",
    "        encrypted_bytes = base64.b64decode(encrypted_base64.encode('utf-8'))\n",
    "       \n",
    "        # Create the AES cipher object in ECB mode for decryption\n",
    "        cipher = AES.new(key, AES.MODE_ECB)\n",
    "       \n",
    "        # Decrypt the data\n",
    "        decrypted_bytes = cipher.decrypt(encrypted_bytes)\n",
    "       \n",
    "        # Remove padding (the padding was added during encryption to make the length a multiple of 16)\n",
    "        decrypted_text = decrypted_bytes.decode('utf-8').rstrip(' ')  # Remove padding\n",
    "       \n",
    "        return decrypted_text\n",
    "    except Exception as e:\n",
    "        return None\n",
    " \n",
    "# Define the encryption key\n",
    "encryption_key = dbutils.secrets.get(scope=\"az_cs_scope\", key=\"lic-no\")\n",
    " \n",
    "# Create UDF for encryption\n",
    "encrypt_lic_no_udf = udf(lambda lic_no: encrypt_lic_no(lic_no, encryption_key), StringType())\n",
    " \n",
    "# Encrypt the lic_no column\n",
    "df_final = df_final.withColumn(\"Lic_No\", encrypt_lic_no_udf(col(\"Lic_No\")))\n",
    " \n",
    "# Create UDF for decryption\n",
    "decrypt_lic_no_udf = udf(lambda encrypted_text: decrypt_lic_no(encrypted_text, encryption_key), StringType())\n",
    " \n",
    "# Decrypt the lic_no_encrypted column\n",
    "# df1 = df.withColumn(\"Lic_No\", decrypt_lic_no_udf(col(\"Lic_No\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24790423-d530-40e4-b7cd-38adf942f903",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_final.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4189c4d-7a46-4637-8b18-4c3e51a914b7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "adding timestamp column"
    }
   },
   "outputs": [],
   "source": [
    "df_final = df_final.withColumn(\"timestamp\", current_timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbad6749-ad25-4856-a3ba-19095010aa67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"fs.azure.account.key.cs0st0rage.dfs.core.windows.net\", ACCOUNT_KEY)\n",
    "\n",
    "delta_table_path_final = \"abfss://silver@cs0st0rage.dfs.core.windows.net/\"\n",
    "\n",
    "df_final.write.format(\"delta\").mode(\"append\").save(delta_table_path_final)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2316592262513663,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Bronze->Silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}